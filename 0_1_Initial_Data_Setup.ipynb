{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Download the Datasets\n",
        "#\n",
        "# This cell downloads the required TEST datasets from Google Drive.\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "# URLs for the datasets, taken from the project plan\n",
        "DATA_URLS = {\n",
        "    \"keypoints\": \"https://drive.google.com/file/d/1g8tzzW5BNPzHXlamuMQOvdwlHRa-29Vp/view?usp=sharing\",\n",
        "    \"rgb_clips\": \"https://drive.google.com/file/d/1qTIXFsu8M55HrCiaGv7vZ7GkdB3ubjaG/view?usp=sharing\"\n",
        "}\n",
        "\n",
        "# Directory to store the development data\n",
        "OUTPUT_DIR = \"dev_test_data\"\n",
        "\n",
        "\n",
        "# --- Download and Extract Files ---\n",
        "for name, url in DATA_URLS.items():\n",
        "    print(f\"--- Processing {name} ---\")\n",
        "\n",
        "    # Let gdown determine the filename and download to the current directory\n",
        "    print(f\"Downloading {name} data...\")\n",
        "    downloaded_file_path = gdown.download(url, quiet=False, fuzzy=True)\n",
        "\n",
        "    if downloaded_file_path is None or not os.path.exists(downloaded_file_path):\n",
        "        print(f\"‚ùå Error: Download failed for {name}. Please check the URL and permissions.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"‚úÖ Download complete: {downloaded_file_path}\")\n",
        "\n",
        "    # --- Unpack Files ---\n",
        "    print(f\"Attempting to unpack {downloaded_file_path}...\")\n",
        "    extracted = False\n",
        "\n",
        "    # Try to extract as a zip file\n",
        "    if zipfile.is_zipfile(downloaded_file_path):\n",
        "        try:\n",
        "            with zipfile.ZipFile(downloaded_file_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(OUTPUT_DIR)\n",
        "            print(f\"‚úÖ Unzipped successfully.\")\n",
        "            extracted = True\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during unzipping: {e}\")\n",
        "\n",
        "    # If not a zip, try to extract as a tar file\n",
        "    elif tarfile.is_tarfile(downloaded_file_path):\n",
        "        try:\n",
        "            with tarfile.open(downloaded_file_path, 'r:*') as tar_ref:\n",
        "                tar_ref.extractall(path=OUTPUT_DIR)\n",
        "            print(f\"‚úÖ Extracted tar archive successfully.\")\n",
        "            extracted = True\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during tar extraction: {e}\")\n",
        "\n",
        "    if not extracted:\n",
        "        print(f\"‚ùå Error: The file '{downloaded_file_path}' is not a recognized zip or tar archive. Manual inspection may be needed.\")\n",
        "\n",
        "    # --- Clean up the downloaded archive file ---\n",
        "    if os.path.exists(downloaded_file_path):\n",
        "        os.remove(downloaded_file_path)\n",
        "        print(f\"Removed archive file: {downloaded_file_path}\\n\")\n",
        "\n",
        "\n",
        "print(\"All dataset operations are complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wEvJ05Ye6Zi",
        "outputId": "dc517c58-7d79-4f0c-fd06-eecb3ea340d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing keypoints ---\n",
            "Downloading keypoints data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1g8tzzW5BNPzHXlamuMQOvdwlHRa-29Vp\n",
            "From (redirected): https://drive.google.com/uc?id=1g8tzzW5BNPzHXlamuMQOvdwlHRa-29Vp&confirm=t&uuid=7ed29dea-277b-4d44-8fc7-c1a2f55c034f\n",
            "To: /content/test_2D_keypoints.tar.gz\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.70G/1.70G [00:17<00:00, 96.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download complete: test_2D_keypoints.tar.gz\n",
            "Attempting to unpack test_2D_keypoints.tar.gz...\n",
            "‚úÖ Extracted tar archive successfully.\n",
            "Removed archive file: test_2D_keypoints.tar.gz\n",
            "\n",
            "--- Processing rgb_clips ---\n",
            "Downloading rgb_clips data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qTIXFsu8M55HrCiaGv7vZ7GkdB3ubjaG\n",
            "From (redirected): https://drive.google.com/uc?id=1qTIXFsu8M55HrCiaGv7vZ7GkdB3ubjaG&confirm=t&uuid=b5ba748b-8a2c-4c50-93b0-ebec6518c27f\n",
            "To: /content/test_rgb_front_clips.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.41G/2.41G [00:38<00:00, 63.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download complete: test_rgb_front_clips.zip\n",
            "Attempting to unpack test_rgb_front_clips.zip...\n",
            "‚úÖ Unzipped successfully.\n",
            "Removed archive file: test_rgb_front_clips.zip\n",
            "\n",
            "All dataset operations are complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Verify Data Setup\n",
        "#\n",
        "# This cell checks if the data folders have been created successfully,\n",
        "# meeting the success criterion.\n",
        "\n",
        "# --- Verification ---\n",
        "print(f\"Verifying contents of '{OUTPUT_DIR}':\")\n",
        "\n",
        "try:\n",
        "    # List the contents of the directory\n",
        "    contents = os.listdir(OUTPUT_DIR)\n",
        "\n",
        "    if contents:\n",
        "        print(\"üéØ Success! The following files/folders are in the development directory:\")\n",
        "        for item in contents:\n",
        "            print(f\"- {item}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: The development directory is empty.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: The directory '{OUTPUT_DIR}' was not found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFE-izPWe_xc",
        "outputId": "2bc2f2b9-2324-4528-f4fe-bef557ed2d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying contents of 'dev_test_data':\n",
            "üéØ Success! The following files/folders are in the development directory:\n",
            "- openpose_output\n",
            "- .ipynb_checkpoints\n",
            "- raw_videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Now is time to save some data to drive\n",
        "#\n",
        "# This cell connects your Google Drive to this Colab notebook.\n",
        "# You will be prompted to authorize this connection.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive mounted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk5PhrQRhvhh",
        "outputId": "57d9f373-1aee-4382-cdb2-500e47d675f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "‚úÖ Google Drive mounted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÊúÄÁªàËß£ÂÜ≥ÊñπÊ°àÔºöÁ≤æÁ°ÆÂàõÂª∫Êï∞ÊçÆÂ≠êÈõÜ\n",
        "#\n",
        "# üìù **ÁõÆÊ†á:** Ê†πÊçÆÊàë‰ª¨Â∑≤Á°ÆËÆ§ÁöÑÊ≠£Á°ÆÊï∞ÊçÆÁªìÊûÑÔºåÂàõÂª∫‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÁõ∏ÂÖ≥Êñá‰ª∂ÔºàJSONÂÖ≥ÈîÆÁÇπ„ÄÅÂéüÂßãËßÜÈ¢ëÁ≠âÔºâÁöÑ„ÄÅÂ∞èËÄåÂÆåÊï¥ÁöÑÂºÄÂèëÂ≠êÈõÜ„ÄÇ\n",
        "#\n",
        "# **Êìç‰Ωú:** Ê≠§ËÑöÊú¨Â∞ÜËá™Âä®‰ªé `openpose_output/json` ‰∏≠ÈÄâÂèñÂâç5‰∏™ËßÜÈ¢ëÂ∫èÂàóÔºåÁÑ∂ÂêéÊâæÂà∞Âπ∂Â§çÂà∂ÂÆÉ‰ª¨ÂØπÂ∫îÁöÑÊâÄÊúâÁõ∏ÂÖ≥Êñá‰ª∂„ÄÇ\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- 1. ÈÖçÁΩÆ (Âü∫‰∫éÊàë‰ª¨Â∑≤Á°ÆËÆ§ÁöÑÊ≠£Á°ÆË∑ØÂæÑ) ---\n",
        "JSON_SOURCE_DIR = 'dev_test_data/openpose_output/json'\n",
        "VIDEO_SOURCE_DIR = 'dev_test_data/openpose_output/video'\n",
        "RAW_VIDEO_SOURCE_DIR = 'dev_test_data/raw_videos'\n",
        "\n",
        "SUBSET_DIR = 'dev_test_data_subset'\n",
        "NUM_SEQUENCES_TO_KEEP = 5 # ÈÄâÊã©5‰∏™Â∫èÂàó‰Ωú‰∏∫Êàë‰ª¨ÁöÑÂºÄÂèëÈõÜÔºåËøô‰∏™Êï∞ÈáèÂÆåÂÖ®Ë∂≥Â§ü\n",
        "\n",
        "print(\"--- ÂºÄÂßãÂàõÂª∫Á≤æÁ°ÆÁöÑÊï∞ÊçÆÂ≠êÈõÜ ---\")\n",
        "\n",
        "# --- 2. Ê∏ÖÁêÜÂπ∂ÂàõÂª∫Â≠êÈõÜÁõÆÂΩïÁªìÊûÑ ---\n",
        "if os.path.exists(SUBSET_DIR):\n",
        "    shutil.rmtree(SUBSET_DIR)\n",
        "    print(f\"Ê∏ÖÈô§‰∫ÜÊóßÁöÑÂ≠êÈõÜÁõÆÂΩï: {SUBSET_DIR}\")\n",
        "\n",
        "# ÂàõÂª∫‰∏éÊ∫êÊï∞ÊçÆÁ±ª‰ººÁöÑÁõÆÂΩïÁªìÊûÑÔºåÊõ¥Ê∏ÖÊô∞\n",
        "subset_json_dir = os.path.join(SUBSET_DIR, 'json_keypoints')\n",
        "subset_video_dir = os.path.join(SUBSET_DIR, 'rendered_videos')\n",
        "subset_raw_video_dir = os.path.join(SUBSET_DIR, 'raw_videos')\n",
        "\n",
        "os.makedirs(subset_json_dir)\n",
        "os.makedirs(subset_video_dir)\n",
        "os.makedirs(subset_raw_video_dir)\n",
        "print(f\"ÂàõÂª∫‰∫ÜÊñ∞ÁöÑÂ≠êÈõÜÁõÆÂΩïÁªìÊûÑ‰∫é: {SUBSET_DIR}\")\n",
        "\n",
        "# --- 3. ÈÄâÊã©Ë¶ÅÂ§çÂà∂ÁöÑËßÜÈ¢ëÂ∫èÂàó ---\n",
        "if not os.path.isdir(JSON_SOURCE_DIR):\n",
        "    print(f\"‚ùå ÈîôËØØ: ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆÊ∫êÁõÆÂΩï '{JSON_SOURCE_DIR}' ‰∏çÂ≠òÂú®ÔºÅÊó†Ê≥ïÁªßÁª≠„ÄÇ\")\n",
        "else:\n",
        "    # Ëé∑ÂèñÊâÄÊúâÂ∫èÂàóÁöÑÂêçÁß∞ÔºàÂç≥jsonÁõÆÂΩï‰∏ãÁöÑÊâÄÊúâÂ≠êÊñá‰ª∂Â§πÔºâÂπ∂ÊéíÂ∫è\n",
        "    all_sequences = sorted([d for d in os.listdir(JSON_SOURCE_DIR) if os.path.isdir(os.path.join(JSON_SOURCE_DIR, d))])\n",
        "\n",
        "    sequences_to_copy = all_sequences[:NUM_SEQUENCES_TO_KEEP]\n",
        "\n",
        "    print(f\"\\nÂú® '{JSON_SOURCE_DIR}' ‰∏≠ÊâæÂà∞ {len(all_sequences)} ‰∏™ËßÜÈ¢ëÂ∫èÂàó„ÄÇ\")\n",
        "    print(f\"Â∞ÜÈÄâÂèñÂâç {len(sequences_to_copy)} ‰∏™‰Ωú‰∏∫Â≠êÈõÜ:\")\n",
        "    for seq_name in sequences_to_copy:\n",
        "        print(f\"  - {seq_name}\")\n",
        "\n",
        "    # --- 4. Â§çÂà∂ÊâÄÊúâÁõ∏ÂÖ≥Êñá‰ª∂ ---\n",
        "    copied_count = 0\n",
        "    for seq_name in sequences_to_copy:\n",
        "        print(f\"\\n--- Ê≠£Âú®Â§ÑÁêÜÂ∫èÂàó: {seq_name} ---\")\n",
        "\n",
        "        # 1. Â§çÂà∂JSONÂÖ≥ÈîÆÁÇπÊñá‰ª∂Â§π\n",
        "        source_json_path = os.path.join(JSON_SOURCE_DIR, seq_name)\n",
        "        dest_json_path = os.path.join(subset_json_dir, seq_name)\n",
        "        if os.path.isdir(source_json_path):\n",
        "            shutil.copytree(source_json_path, dest_json_path)\n",
        "            print(f\"    ‚úÖ Â∑≤Â§çÂà∂ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆ (JSONs)\")\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Ë≠¶Âëä: Êú™ÊâæÂà∞ÂÖ≥ÈîÆÁÇπÊñá‰ª∂Â§π {source_json_path}\")\n",
        "\n",
        "        # 2. Â§çÂà∂Ê∏≤ÊüìÂêéÁöÑËßÜÈ¢ë\n",
        "        # ËßÜÈ¢ëÊñá‰ª∂ÂêçÈÄöÂ∏∏ÊòØÂ∫èÂàóÂêç + .mp4\n",
        "        video_filename = f\"{seq_name}.mp4\"\n",
        "        source_video_path = os.path.join(VIDEO_SOURCE_DIR, video_filename)\n",
        "        dest_video_path = os.path.join(subset_video_dir, video_filename)\n",
        "        if os.path.exists(source_video_path):\n",
        "            shutil.copy(source_video_path, dest_video_path)\n",
        "            print(f\"    ‚úÖ Â∑≤Â§çÂà∂Ê∏≤ÊüìËßÜÈ¢ë\")\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Ë≠¶Âëä: Êú™ÊâæÂà∞Ê∏≤ÊüìËßÜÈ¢ë {source_video_path}\")\n",
        "\n",
        "        # 3. Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\n",
        "        raw_video_filename = f\"{seq_name}.mp4\" # ÂÅáËÆæÂéüÂßãËßÜÈ¢ëÂíåÂ∫èÂàóÂêç‰πüÂØπÂ∫î\n",
        "        source_raw_video_path = os.path.join(RAW_VIDEO_SOURCE_DIR, raw_video_filename)\n",
        "        dest_raw_video_path = os.path.join(subset_raw_video_dir, raw_video_filename)\n",
        "        if os.path.exists(source_raw_video_path):\n",
        "            shutil.copy(source_raw_video_path, dest_raw_video_path)\n",
        "            print(f\"    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\")\n",
        "        else:\n",
        "            # ÂéüÂßãËßÜÈ¢ëÁöÑÊñá‰ª∂ÂêçÂèØËÉΩÊ≤°Êúâ-rgb_frontÂêéÁºÄÔºåÂ∞ùËØïÂéªÊéâÂÆÉ\n",
        "            base_name = seq_name.replace('-rgb_front', '')\n",
        "            raw_video_filename_alt = f\"{base_name}.mp4\"\n",
        "            source_raw_video_path_alt = os.path.join(RAW_VIDEO_SOURCE_DIR, raw_video_filename_alt)\n",
        "            if os.path.exists(source_raw_video_path_alt):\n",
        "                 shutil.copy(source_raw_video_path_alt, os.path.join(subset_raw_video_dir, raw_video_filename_alt))\n",
        "                 print(f\"    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë (Â§áÁî®ÂêçÁß∞: {raw_video_filename_alt})\")\n",
        "            else:\n",
        "                print(f\"    ‚ö†Ô∏è Ë≠¶Âëä: Êú™ÊâæÂà∞ÂéüÂßãËßÜÈ¢ë {source_raw_video_path} Êàñ {source_raw_video_path_alt}\")\n",
        "\n",
        "        copied_count += 1\n",
        "\n",
        "    print(f\"\\n--- üéØ Êìç‰ΩúÂÆåÊàêÔºÅ---\")\n",
        "    print(f\"ÊàêÂäüÂ§ÑÁêÜ‰∫Ü {copied_count} ‰∏™ËßÜÈ¢ëÂ∫èÂàó„ÄÇ\")\n",
        "    print(f\"‰∏Ä‰∏™ÂÆåÊï¥„ÄÅÂ∞èÂ∑ßÁöÑÂºÄÂèëÊï∞ÊçÆÈõÜÂ∑≤Âú® '{SUBSET_DIR}' ‰∏≠ÂáÜÂ§áÂ∞±Áª™„ÄÇ\")\n",
        "    print(\"Áé∞Âú®ÔºåÊÇ®ÂèØ‰ª•ËøêË°å‚ÄúÊâìÂåÖÂπ∂‰∏ä‰º†Âà∞Ë∞∑Ê≠åÁ°¨Áõò‚ÄùÁöÑÂçïÂÖÉÊ†ºÊù•Ê∞∏‰πÖ‰øùÂ≠òÂÆÉ‰∫Ü„ÄÇ\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv6hNeTRAMgo",
        "outputId": "8968f148-a2c3-4dc5-b1ea-53ba57f8099b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ÂºÄÂßãÂàõÂª∫Á≤æÁ°ÆÁöÑÊï∞ÊçÆÂ≠êÈõÜ ---\n",
            "Ê∏ÖÈô§‰∫ÜÊóßÁöÑÂ≠êÈõÜÁõÆÂΩï: dev_test_data_subset\n",
            "ÂàõÂª∫‰∫ÜÊñ∞ÁöÑÂ≠êÈõÜÁõÆÂΩïÁªìÊûÑ‰∫é: dev_test_data_subset\n",
            "\n",
            "Âú® 'dev_test_data/openpose_output/json' ‰∏≠ÊâæÂà∞ 2343 ‰∏™ËßÜÈ¢ëÂ∫èÂàó„ÄÇ\n",
            "Â∞ÜÈÄâÂèñÂâç 5 ‰∏™‰Ωú‰∏∫Â≠êÈõÜ:\n",
            "  - -fZc293MpJk_0-1-rgb_front\n",
            "  - -fZc293MpJk_2-1-rgb_front\n",
            "  - -fZc293MpJk_3-1-rgb_front\n",
            "  - -fZc293MpJk_4-1-rgb_front\n",
            "  - -fZc293MpJk_5-1-rgb_front\n",
            "\n",
            "--- Ê≠£Âú®Â§ÑÁêÜÂ∫èÂàó: -fZc293MpJk_0-1-rgb_front ---\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆ (JSONs)\n",
            "    ‚úÖ Â∑≤Â§çÂà∂Ê∏≤ÊüìËßÜÈ¢ë\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\n",
            "\n",
            "--- Ê≠£Âú®Â§ÑÁêÜÂ∫èÂàó: -fZc293MpJk_2-1-rgb_front ---\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆ (JSONs)\n",
            "    ‚úÖ Â∑≤Â§çÂà∂Ê∏≤ÊüìËßÜÈ¢ë\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\n",
            "\n",
            "--- Ê≠£Âú®Â§ÑÁêÜÂ∫èÂàó: -fZc293MpJk_3-1-rgb_front ---\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆ (JSONs)\n",
            "    ‚úÖ Â∑≤Â§çÂà∂Ê∏≤ÊüìËßÜÈ¢ë\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\n",
            "\n",
            "--- Ê≠£Âú®Â§ÑÁêÜÂ∫èÂàó: -fZc293MpJk_4-1-rgb_front ---\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆ (JSONs)\n",
            "    ‚úÖ Â∑≤Â§çÂà∂Ê∏≤ÊüìËßÜÈ¢ë\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\n",
            "\n",
            "--- Ê≠£Âú®Â§ÑÁêÜÂ∫èÂàó: -fZc293MpJk_5-1-rgb_front ---\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂÖ≥ÈîÆÁÇπÊï∞ÊçÆ (JSONs)\n",
            "    ‚úÖ Â∑≤Â§çÂà∂Ê∏≤ÊüìËßÜÈ¢ë\n",
            "    ‚úÖ Â∑≤Â§çÂà∂ÂéüÂßãËßÜÈ¢ë\n",
            "\n",
            "--- üéØ Êìç‰ΩúÂÆåÊàêÔºÅ---\n",
            "ÊàêÂäüÂ§ÑÁêÜ‰∫Ü 5 ‰∏™ËßÜÈ¢ëÂ∫èÂàó„ÄÇ\n",
            "‰∏Ä‰∏™ÂÆåÊï¥„ÄÅÂ∞èÂ∑ßÁöÑÂºÄÂèëÊï∞ÊçÆÈõÜÂ∑≤Âú® 'dev_test_data_subset' ‰∏≠ÂáÜÂ§áÂ∞±Áª™„ÄÇ\n",
            "Áé∞Âú®ÔºåÊÇ®ÂèØ‰ª•ËøêË°å‚ÄúÊâìÂåÖÂπ∂‰∏ä‰º†Âà∞Ë∞∑Ê≠åÁ°¨Áõò‚ÄùÁöÑÂçïÂÖÉÊ†ºÊù•Ê∞∏‰πÖ‰øùÂ≠òÂÆÉ‰∫Ü„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÊâìÂåÖÂºÄÂèëÂ≠êÈõÜÂπ∂‰øùÂ≠òÂà∞Ë∞∑Ê≠åÁ°¨Áõò\n",
        "#\n",
        "# üìù **ÁõÆÊ†á:** Â∞ÜÊàë‰ª¨ÊúÄÁªàÂàõÂª∫ÁöÑ„ÄÅÊ≠£Á°ÆÁöÑ 'dev_test_data_subset' Êñá‰ª∂Â§πÊâìÂåÖÊàêzipÊñá‰ª∂ÔºåÂπ∂Ê∞∏‰πÖ‰øùÂ≠òÂú®ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò‰∏≠„ÄÇ\n",
        "#\n",
        "# **Êìç‰Ωú:** Ê≠§ÂçïÂÖÉÂ∞ÜËá™Âä®ÂÆåÊàêÊåÇËΩΩÁ°¨Áõò„ÄÅÊâìÂåÖÂíåÂ§çÂà∂ÁöÑÂÖ®ËøáÁ®ã„ÄÇ\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# --- 1. ÈÖçÁΩÆ ---\n",
        "SOURCE_DIR_TO_PACKAGE = 'dev_test_data_subset'\n",
        "ARCHIVE_NAME = 'dev_test_data_subset_archive'\n",
        "# ÊÇ®ÂèØ‰ª•Ëá™ÂÆö‰πâ‰øùÂ≠òÂú®Ë∞∑Ê≠åÁ°¨ÁõòÈáåÁöÑÊñá‰ª∂Â§πÂêçÁß∞\n",
        "DRIVE_FOLDER_PATH = '/content/drive/MyDrive/Sign_Language_Project_Dev_Data'\n",
        "\n",
        "# --- 2. Ê£ÄÊü•Ê∫êÊñá‰ª∂Â§πÊòØÂê¶Â≠òÂú® ---\n",
        "if not os.path.isdir(SOURCE_DIR_TO_PACKAGE):\n",
        "    print(f\"‚ùå ÈîôËØØ: Ê∫êÊñá‰ª∂Â§π '{SOURCE_DIR_TO_PACKAGE}' ‰∏çÂ≠òÂú®„ÄÇËØ∑Á°Æ‰øù‰∏ä‰∏ÄÊ≠•Â∑≤ÊàêÂäüËøêË°å„ÄÇ\")\n",
        "else:\n",
        "    # --- 3. ÊâìÂåÖÊñá‰ª∂Â§π‰∏∫ .zip Êñá‰ª∂ ---\n",
        "    print(f\"Ê≠£Âú®Â∞Ü '{SOURCE_DIR_TO_PACKAGE}' ÊâìÂåÖÊàê '{ARCHIVE_NAME}.zip'...\")\n",
        "    shutil.make_archive(ARCHIVE_NAME, 'zip', SOURCE_DIR_TO_PACKAGE)\n",
        "    print(\"‚úÖ ÊâìÂåÖÊàêÂäüÔºÅ\")\n",
        "\n",
        "    # --- 4. ÊåÇËΩΩË∞∑Ê≠åÁ°¨Áõò ---\n",
        "    print(\"\\nÊ≠£Âú®ËøûÊé•Âà∞ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # --- 5. Âú®Ë∞∑Ê≠åÁ°¨Áõò‰∏≠ÂàõÂª∫ÁõÆÊ†áÊñá‰ª∂Â§π (Â¶ÇÊûú‰∏çÂ≠òÂú®) ---\n",
        "    if not os.path.exists(DRIVE_FOLDER_PATH):\n",
        "        print(f\"Âú®ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò‰∏≠ÂàõÂª∫Êñ∞Êñá‰ª∂Â§π: {DRIVE_FOLDER_PATH}\")\n",
        "        os.makedirs(DRIVE_FOLDER_PATH)\n",
        "\n",
        "    # --- 6. Â§çÂà∂ÊâìÂåÖÂ•ΩÁöÑÊñá‰ª∂Âà∞Ë∞∑Ê≠åÁ°¨Áõò ---\n",
        "    source_file_path = f\"{ARCHIVE_NAME}.zip\"\n",
        "    destination_path = os.path.join(DRIVE_FOLDER_PATH, source_file_path)\n",
        "\n",
        "    print(f\"\\nÊ≠£Âú®Â§çÂà∂Êñá‰ª∂Âà∞: {destination_path}...\")\n",
        "    if os.path.exists(source_file_path):\n",
        "        shutil.copy(source_file_path, destination_path)\n",
        "        print(f\"\\n--- üéØ Êìç‰ΩúÊàêÂäüÔºÅ---\")\n",
        "        print(f\"ÂºÄÂèëÊï∞ÊçÆÈõÜ '{source_file_path}' Â∑≤ÊàêÂäü‰øùÂ≠òÂà∞ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò‰∏≠ÔºÅ\")\n",
        "        print(\"ÂêéÁª≠ÊÇ®ÂèØ‰ª•Áõ¥Êé•‰ªéË∞∑Ê≠åÁ°¨Áõò‰∏≠‰∏ãËΩΩÂπ∂Ëß£ÂéãËøô‰∏™Êñá‰ª∂ÔºåÊó†ÈúÄÂÜçÈáçÂ§ç‰∏ãËΩΩÂéüÂßãÊï∞ÊçÆ„ÄÇ\")\n",
        "    else:\n",
        "        print(f\"‚ùå ÈîôËØØ: Êú™ÊâæÂà∞ÊâìÂåÖÂ•ΩÁöÑÊñá‰ª∂ '{source_file_path}'„ÄÇ\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4tVAUmQGC8qX",
        "outputId": "100b809f-6011-499e-e683-6b4c082f89e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ê≠£Âú®Â∞Ü 'dev_test_data_subset' ÊâìÂåÖÊàê 'dev_test_data_subset_archive.zip'...\n",
            "‚úÖ ÊâìÂåÖÊàêÂäüÔºÅ\n",
            "\n",
            "Ê≠£Âú®ËøûÊé•Âà∞ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Âú®ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò‰∏≠ÂàõÂª∫Êñ∞Êñá‰ª∂Â§π: /content/drive/MyDrive/Sign_Language_Project_Dev_Data\n",
            "\n",
            "Ê≠£Âú®Â§çÂà∂Êñá‰ª∂Âà∞: /content/drive/MyDrive/Sign_Language_Project_Dev_Data/dev_test_data_subset_archive.zip...\n",
            "\n",
            "--- üéØ Êìç‰ΩúÊàêÂäüÔºÅ---\n",
            "ÂºÄÂèëÊï∞ÊçÆÈõÜ 'dev_test_data_subset_archive.zip' Â∑≤ÊàêÂäü‰øùÂ≠òÂà∞ÊÇ®ÁöÑË∞∑Ê≠åÁ°¨Áõò‰∏≠ÔºÅ\n",
            "ÂêéÁª≠ÊÇ®ÂèØ‰ª•Áõ¥Êé•‰ªéË∞∑Ê≠åÁ°¨Áõò‰∏≠‰∏ãËΩΩÂπ∂Ëß£ÂéãËøô‰∏™Êñá‰ª∂ÔºåÊó†ÈúÄÂÜçÈáçÂ§ç‰∏ãËΩΩÂéüÂßãÊï∞ÊçÆ„ÄÇ\n"
          ]
        }
      ]
    }
  ]
}
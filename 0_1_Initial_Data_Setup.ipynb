{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Download the Datasets\n",
        "#\n",
        "# This cell downloads the required TEST datasets from Google Drive.\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "# URLs for the datasets, taken from the project plan\n",
        "DATA_URLS = {\n",
        "    \"keypoints\": \"https://drive.google.com/file/d/1g8tzzW5BNPzHXlamuMQOvdwlHRa-29Vp/view?usp=sharing\",\n",
        "    \"rgb_clips\": \"https://drive.google.com/file/d/1qTIXFsu8M55HrCiaGv7vZ7GkdB3ubjaG/view?usp=sharing\"\n",
        "}\n",
        "\n",
        "# Directory to store the development data\n",
        "OUTPUT_DIR = \"dev_test_data\"\n",
        "\n",
        "\n",
        "# --- Download and Extract Files ---\n",
        "for name, url in DATA_URLS.items():\n",
        "    print(f\"--- Processing {name} ---\")\n",
        "\n",
        "    # Let gdown determine the filename and download to the current directory\n",
        "    print(f\"Downloading {name} data...\")\n",
        "    downloaded_file_path = gdown.download(url, quiet=False, fuzzy=True)\n",
        "\n",
        "    if downloaded_file_path is None or not os.path.exists(downloaded_file_path):\n",
        "        print(f\"‚ùå Error: Download failed for {name}. Please check the URL and permissions.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"‚úÖ Download complete: {downloaded_file_path}\")\n",
        "\n",
        "    # --- Unpack Files ---\n",
        "    print(f\"Attempting to unpack {downloaded_file_path}...\")\n",
        "    extracted = False\n",
        "\n",
        "    # Try to extract as a zip file\n",
        "    if zipfile.is_zipfile(downloaded_file_path):\n",
        "        try:\n",
        "            with zipfile.ZipFile(downloaded_file_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(OUTPUT_DIR)\n",
        "            print(f\"‚úÖ Unzipped successfully.\")\n",
        "            extracted = True\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during unzipping: {e}\")\n",
        "\n",
        "    # If not a zip, try to extract as a tar file\n",
        "    elif tarfile.is_tarfile(downloaded_file_path):\n",
        "        try:\n",
        "            with tarfile.open(downloaded_file_path, 'r:*') as tar_ref:\n",
        "                tar_ref.extractall(path=OUTPUT_DIR)\n",
        "            print(f\"‚úÖ Extracted tar archive successfully.\")\n",
        "            extracted = True\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during tar extraction: {e}\")\n",
        "\n",
        "    if not extracted:\n",
        "        print(f\"‚ùå Error: The file '{downloaded_file_path}' is not a recognized zip or tar archive. Manual inspection may be needed.\")\n",
        "\n",
        "    # --- Clean up the downloaded archive file ---\n",
        "    if os.path.exists(downloaded_file_path):\n",
        "        os.remove(downloaded_file_path)\n",
        "        print(f\"Removed archive file: {downloaded_file_path}\\n\")\n",
        "\n",
        "\n",
        "print(\"All dataset operations are complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wEvJ05Ye6Zi",
        "outputId": "dc517c58-7d79-4f0c-fd06-eecb3ea340d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing keypoints ---\n",
            "Downloading keypoints data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1g8tzzW5BNPzHXlamuMQOvdwlHRa-29Vp\n",
            "From (redirected): https://drive.google.com/uc?id=1g8tzzW5BNPzHXlamuMQOvdwlHRa-29Vp&confirm=t&uuid=7ed29dea-277b-4d44-8fc7-c1a2f55c034f\n",
            "To: /content/test_2D_keypoints.tar.gz\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.70G/1.70G [00:17<00:00, 96.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download complete: test_2D_keypoints.tar.gz\n",
            "Attempting to unpack test_2D_keypoints.tar.gz...\n",
            "‚úÖ Extracted tar archive successfully.\n",
            "Removed archive file: test_2D_keypoints.tar.gz\n",
            "\n",
            "--- Processing rgb_clips ---\n",
            "Downloading rgb_clips data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qTIXFsu8M55HrCiaGv7vZ7GkdB3ubjaG\n",
            "From (redirected): https://drive.google.com/uc?id=1qTIXFsu8M55HrCiaGv7vZ7GkdB3ubjaG&confirm=t&uuid=b5ba748b-8a2c-4c50-93b0-ebec6518c27f\n",
            "To: /content/test_rgb_front_clips.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.41G/2.41G [00:38<00:00, 63.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download complete: test_rgb_front_clips.zip\n",
            "Attempting to unpack test_rgb_front_clips.zip...\n",
            "‚úÖ Unzipped successfully.\n",
            "Removed archive file: test_rgb_front_clips.zip\n",
            "\n",
            "All dataset operations are complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Verify Data Setup\n",
        "#\n",
        "# This cell checks if the data folders have been created successfully,\n",
        "# meeting the success criterion.\n",
        "\n",
        "# --- Verification ---\n",
        "print(f\"Verifying contents of '{OUTPUT_DIR}':\")\n",
        "\n",
        "try:\n",
        "    # List the contents of the directory\n",
        "    contents = os.listdir(OUTPUT_DIR)\n",
        "\n",
        "    if contents:\n",
        "        print(\"üéØ Success! The following files/folders are in the development directory:\")\n",
        "        for item in contents:\n",
        "            print(f\"- {item}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: The development directory is empty.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: The directory '{OUTPUT_DIR}' was not found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFE-izPWe_xc",
        "outputId": "2bc2f2b9-2324-4528-f4fe-bef557ed2d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying contents of 'dev_test_data':\n",
            "üéØ Success! The following files/folders are in the development directory:\n",
            "- openpose_output\n",
            "- .ipynb_checkpoints\n",
            "- raw_videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Now is time to save some data to drive\n",
        "#\n",
        "# This cell connects your Google Drive to this Colab notebook.\n",
        "# You will be prompted to authorize this connection.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive mounted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk5PhrQRhvhh",
        "outputId": "57d9f373-1aee-4382-cdb2-500e47d675f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "‚úÖ Google Drive mounted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Final Solution: Accurately Subset Data\n",
        "#\n",
        "# üìù **Goal:** Create a small but complete development subset with all relevant files (JSON keypoints, raw videos, etc.) based on the data structure we have confirmed is correct.\n",
        "#\n",
        "# **Action:** This script will automatically pick the first 5 video sequences from `openpose_output/json` and then find and copy all their corresponding relevant files.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- 1. Configuration (based on confirmed correct paths) ---\n",
        "JSON_SOURCE_DIR = 'dev_test_data/openpose_output/json'\n",
        "VIDEO_SOURCE_DIR = 'dev_test_data/openpose_output/video'\n",
        "RAW_VIDEO_SOURCE_DIR = 'dev_test_data/raw_videos'\n",
        "\n",
        "SUBSET_DIR = 'dev_test_data_subset'\n",
        "NUM_SEQUENCES_TO_KEEP = 5 # Select 5 sequences as our development set, this quantity is entirely sufficient\n",
        "\n",
        "print(\"--- Starting to create precise data subsets ---\")\n",
        "\n",
        "# --- 2. Clean and Create Subset Directory Structure ---\n",
        "if os.path.exists(SUBSET_DIR):\n",
        "    shutil.rmtree(SUBSET_DIR)\n",
        "    print(f\"Cleaned up old subset directory: {SUBSET_DIR}\")\n",
        "\n",
        "# Create a directory structure similar to the source data for clarity\n",
        "subset_json_dir = os.path.join(SUBSET_DIR, 'json_keypoints')\n",
        "subset_video_dir = os.path.join(SUBSET_DIR, 'rendered_videos')\n",
        "subset_raw_video_dir = os.path.join(SUBSET_DIR, 'raw_videos')\n",
        "\n",
        "os.makedirs(subset_json_dir)\n",
        "os.makedirs(subset_video_dir)\n",
        "os.makedirs(subset_raw_video_dir)\n",
        "print(f\"Created new subset directory structure at: {SUBSET_DIR}\")\n",
        "\n",
        "# --- 3. Select Video Sequences to Copy ---\n",
        "if not os.path.isdir(JSON_SOURCE_DIR):\n",
        "    print(f\"‚ùå Error: Keypoint data source directory '{JSON_SOURCE_DIR}' does not exist! Cannot proceed.\")\n",
        "else:\n",
        "    # Get all sequence names (i.e., all subfolders under the json directory) and sort them\n",
        "    all_sequences = sorted([d for d in os.listdir(JSON_SOURCE_DIR) if os.path.isdir(os.path.join(JSON_SOURCE_DIR, d))])\n",
        "\n",
        "    sequences_to_copy = all_sequences[:NUM_SEQUENCES_TO_KEEP]\n",
        "\n",
        "    print(f\"\\nFound {len(all_sequences)} video sequences in '{JSON_SOURCE_DIR}'.\")\n",
        "    print(f\"Selecting the first {len(sequences_to_copy)} as the subset:\")\n",
        "    for seq_name in sequences_to_copy:\n",
        "        print(f\"  - {seq_name}\")\n",
        "\n",
        "    # --- 4. Copy All Related Files ---\n",
        "    copied_count = 0\n",
        "    for seq_name in sequences_to_copy:\n",
        "        print(f\"\\n--- Processing sequence: {seq_name} ---\")\n",
        "\n",
        "        # 1. Copy JSON keypoint folder\n",
        "        source_json_path = os.path.join(JSON_SOURCE_DIR, seq_name)\n",
        "        dest_json_path = os.path.join(subset_json_dir, seq_name)\n",
        "        if os.path.isdir(source_json_path):\n",
        "            shutil.copytree(source_json_path, dest_json_path)\n",
        "            print(f\"    ‚úÖ Keypoint data (JSONs) copied\")\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Warning: Keypoint folder not found {source_json_path}\")\n",
        "\n",
        "        # 2. Copy rendered video\n",
        "        # Video filenames are usually sequence_name + .mp4\n",
        "        video_filename = f\"{seq_name}.mp4\"\n",
        "        source_video_path = os.path.join(VIDEO_SOURCE_DIR, video_filename)\n",
        "        dest_video_path = os.path.join(subset_video_dir, video_filename)\n",
        "        if os.path.exists(source_video_path):\n",
        "            shutil.copy(source_video_path, dest_video_path)\n",
        "            print(f\"    ‚úÖ Rendered video copied\")\n",
        "        else:\n",
        "            print(f\"    ‚ö†Ô∏è Warning: Rendered video not found {source_video_path}\")\n",
        "\n",
        "        # 3. Copy raw video\n",
        "        raw_video_filename = f\"{seq_name}.mp4\" # Assume raw video and sequence name also correspond\n",
        "        source_raw_video_path = os.path.join(RAW_VIDEO_SOURCE_DIR, raw_video_filename)\n",
        "        dest_raw_video_path = os.path.join(subset_raw_video_dir, raw_video_filename)\n",
        "        if os.path.exists(source_raw_video_path):\n",
        "            shutil.copy(source_raw_video_path, dest_raw_video_path)\n",
        "            print(f\"    ‚úÖ Raw video copied\")\n",
        "        else:\n",
        "            # Raw video filenames might not have the -rgb_front suffix, try removing it\n",
        "            base_name = seq_name.replace('-rgb_front', '')\n",
        "            raw_video_filename_alt = f\"{base_name}.mp4\"\n",
        "            source_raw_video_path_alt = os.path.join(RAW_VIDEO_SOURCE_DIR, raw_video_filename_alt)\n",
        "            if os.path.exists(source_raw_video_path_alt):\n",
        "                 shutil.copy(source_raw_video_path_alt, os.path.join(subset_raw_video_dir, raw_video_filename_alt))\n",
        "                 print(f\"    ‚úÖ Raw video copied (alternate name: {raw_video_filename_alt})\")\n",
        "            else:\n",
        "                print(f\"    ‚ö†Ô∏è Warning: Raw video not found {source_raw_video_path} or {source_raw_video_path_alt}\")\n",
        "\n",
        "        copied_count += 1\n",
        "\n",
        "    print(f\"\\n--- üéØ Operation Complete! ---\")\n",
        "    print(f\"Successfully processed {copied_count} video sequences.\")\n",
        "    print(f\"A complete, compact development dataset is ready in '{SUBSET_DIR}'.\")\n",
        "    print(\"Now, you can run the 'Package and Upload to Google Drive' cell to save it permanently.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv6hNeTRAMgo",
        "outputId": "8968f148-a2c3-4dc5-b1ea-53ba57f8099b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting to create precise data subsets ---\n",
            "Cleaned up old subset directory: dev_test_data_subset\n",
            "Created new subset directory structure at: dev_test_data_subset\n",
            "\n",
            "Found 2343 video sequences in 'dev_test_data/openpose_output/json'.\n",
            "Selecting the first 5 as the subset:\n",
            "  - -fZc293MpJk_0-1-rgb_front\n",
            "  - -fZc293MpJk_2-1-rgb_front\n",
            "  - -fZc293MpJk_3-1-rgb_front\n",
            "  - -fZc293MpJk_4-1-rgb_front\n",
            "  - -fZc293MpJk_5-1-rgb_front\n",
            "\n",
            "--- Processing sequence: -fZc293MpJk_0-1-rgb_front ---\n",
            "    ‚úÖ Keypoint data (JSONs) copied\n",
            "    ‚úÖ Rendered video copied\n",
            "    ‚úÖ Raw video copied\n",
            "\n",
            "--- Processing sequence: -fZc293MpJk_2-1-rgb_front ---\n",
            "    ‚úÖ Keypoint data (JSONs) copied\n",
            "    ‚úÖ Rendered video copied\n",
            "    ‚úÖ Raw video copied\n",
            "\n",
            "--- Processing sequence: -fZc293MpJk_3-1-rgb_front ---\n",
            "    ‚úÖ Keypoint data (JSONs) copied\n",
            "    ‚úÖ Rendered video copied\n",
            "    ‚úÖ Raw video copied\n",
            "\n",
            "--- Processing sequence: -fZc293MpJk_4-1-rgb_front ---\n",
            "    ‚úÖ Keypoint data (JSONs) copied\n",
            "    ‚úÖ Rendered video copied\n",
            "    ‚úÖ Raw video copied\n",
            "\n",
            "--- Processing sequence: -fZc293MpJk_5-1-rgb_front ---\n",
            "    ‚úÖ Keypoint data (JSONs) copied\n",
            "    ‚úÖ Rendered video copied\n",
            "    ‚úÖ Raw video copied\n",
            "\n",
            "--- üéØ Operation Complete! ---\n",
            "Successfully processed 5 video sequences.\n",
            "A complete, compact development dataset is ready in 'dev_test_data_subset'.\n",
            "Now, you can run the 'Package and Upload to Google Drive' cell to save it permanently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Package Development Subset and Save to Google Drive\n",
        "#\n",
        "# üìù **Goal:** Package the final, correct 'dev_test_data_subset' folder into a zip file and permanently save it to your Google Drive.\n",
        "#\n",
        "# **Action:** This cell will automatically complete the entire process of mounting Drive, packaging, and copying.\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "SOURCE_DIR_TO_PACKAGE = 'dev_test_data_subset'\n",
        "ARCHIVE_NAME = 'dev_test_data_subset_archive'\n",
        "# You can customize the folder name saved in Google Drive\n",
        "DRIVE_FOLDER_PATH = '/content/drive/MyDrive/Sign_Language_Project_Dev_Data'\n",
        "\n",
        "# --- 2. Check if Source Folder Exists ---\n",
        "if not os.path.isdir(SOURCE_DIR_TO_PACKAGE):\n",
        "    print(f\"‚ùå Error: Source folder '{SOURCE_DIR_TO_PACKAGE}' does not exist. Please ensure the previous step ran successfully.\")\n",
        "else:\n",
        "    # --- 3. Package the Folder as a .zip File ---\n",
        "    print(f\"Packaging '{SOURCE_DIR_TO_PACKAGE}' into '{ARCHIVE_NAME}.zip'...\")\n",
        "    shutil.make_archive(ARCHIVE_NAME, 'zip', SOURCE_DIR_TO_PACKAGE)\n",
        "    print(\"‚úÖ Packaging successful!\")\n",
        "\n",
        "    # --- 4. Mount Google Drive ---\n",
        "    print(\"\\nConnecting to your Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # --- 5. Create Destination Folder in Google Drive (if it doesn't exist) ---\n",
        "    if not os.path.exists(DRIVE_FOLDER_PATH):\n",
        "        print(f\"Creating new folder in your Google Drive: {DRIVE_FOLDER_PATH}\")\n",
        "        os.makedirs(DRIVE_FOLDER_PATH)\n",
        "\n",
        "    # --- 6. Copy the Packaged File to Google Drive ---\n",
        "    source_file_path = f\"{ARCHIVE_NAME}.zip\"\n",
        "    destination_path = os.path.join(DRIVE_FOLDER_PATH, source_file_path)\n",
        "\n",
        "    print(f\"\\nCopying file to: {destination_path}...\")\n",
        "    if os.path.exists(source_file_path):\n",
        "        shutil.copy(source_file_path, destination_path)\n",
        "        print(f\"\\n--- üéØ Operation Successful! ---\")\n",
        "        print(f\"Development dataset '{source_file_path}' successfully saved to your Google Drive!\")\n",
        "        print(\"You can now directly download and extract this file from Google Drive in the future, without needing to re-download the original data.\")\n",
        "    else:\n",
        "        print(f\"‚ùå Error: Packaged file '{source_file_path}' not found.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4tVAUmQGC8qX",
        "outputId": "100b809f-6011-499e-e683-6b4c082f89e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Packaging 'dev_test_data_subset' into 'dev_test_data_subset_archive.zip'...\n",
            "‚úÖ Packaging successful!\n",
            "\n",
            "Connecting to your Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Creating new folder in your Google Drive: /content/drive/MyDrive/Sign_Language_Project_Dev_Data\n",
            "\n",
            "Copying file to: /content/drive/MyDrive/Sign_Language_Project_Dev_Data/dev_test_data_subset_archive.zip...\n",
            "\n",
            "--- üéØ Operation Successful! ---\n",
            "Development dataset 'dev_test_data_subset_archive.zip' successfully saved to your Google Drive!\n",
            "You can now directly download and extract this file from Google Drive in the future, without needing to re-download the original data.\n"
          ]
        }
      ]
    }
  ]
}
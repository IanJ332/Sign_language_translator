{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z53Dfg0KiZGE",
        "outputId": "3cde74cc-83ef-48f1-e906-c4dd430d3db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "\n",
            "Extracting /content/drive/MyDrive/Sign_Language_Project_Dev_Data/dev_test_data_subset_archive.zip...\n",
            "Extraction complete. Data is in the 'dev_test_data' folder.\n",
            "\n",
            "--- Verifying Extracted Contents ---\n",
            "  Subdirectories: ['json_keypoints', 'rendered_videos', 'raw_videos']\n",
            "\n",
            "Folder: dev_test_data/json_keypoints\n",
            "  Subdirectories: ['-fZc293MpJk_0-1-rgb_front', '-fZc293MpJk_2-1-rgb_front', '-fZc293MpJk_4-1-rgb_front', '-fZc293MpJk_3-1-rgb_front', '-fZc293MpJk_5-1-rgb_front']\n",
            "\n",
            "Folder: dev_test_data/json_keypoints/-fZc293MpJk_0-1-rgb_front\n",
            "  Contains 17 JSON files (e.g., -fZc293MpJk_0-1-rgb_front_000000000006_keypoints.json)\n",
            "\n",
            "Folder: dev_test_data/json_keypoints/-fZc293MpJk_2-1-rgb_front\n",
            "  Contains 412 JSON files (e.g., -fZc293MpJk_2-1-rgb_front_000000000145_keypoints.json)\n",
            "\n",
            "Folder: dev_test_data/json_keypoints/-fZc293MpJk_4-1-rgb_front\n",
            "  Contains 398 JSON files (e.g., -fZc293MpJk_4-1-rgb_front_000000000357_keypoints.json)\n",
            "\n",
            "Folder: dev_test_data/json_keypoints/-fZc293MpJk_3-1-rgb_front\n",
            "  Contains 399 JSON files (e.g., -fZc293MpJk_3-1-rgb_front_000000000047_keypoints.json)\n",
            "\n",
            "Folder: dev_test_data/json_keypoints/-fZc293MpJk_5-1-rgb_front\n",
            "  Contains 294 JSON files (e.g., -fZc293MpJk_5-1-rgb_front_000000000196_keypoints.json)\n",
            "\n",
            "Folder: dev_test_data/rendered_videos\n",
            "  Files:\n",
            "    - -fZc293MpJk_5-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_0-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_3-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_4-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_2-1-rgb_front.mp4\n",
            "\n",
            "Folder: dev_test_data/raw_videos\n",
            "  Files:\n",
            "    - -fZc293MpJk_5-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_0-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_3-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_4-1-rgb_front.mp4\n",
            "    - -fZc293MpJk_2-1-rgb_front.mp4\n",
            "\n",
            "--- Verification Finished ---\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# --- Step 1: Mount Google Drive ---\n",
        "# This will prompt you for authorization.\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "# --- Step 2: Define File Paths ---\n",
        "# The path now starts from '/content/drive/MyDrive/' which is the root of your drive.\n",
        "drive_zip_path = '/content/drive/MyDrive/Sign_Language_Project_Dev_Data/dev_test_data_subset_archive.zip'\n",
        "extract_path = 'dev_test_data'\n",
        "\n",
        "# --- Step 3: Unzip the File ---\n",
        "# Create the extraction directory if it doesn't exist\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "print(f\"\\nExtracting {drive_zip_path}...\")\n",
        "# Verify the zip file exists before trying to open it\n",
        "if os.path.exists(drive_zip_path):\n",
        "    with zipfile.ZipFile(drive_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Extraction complete. Data is in the '{extract_path}' folder.\")\n",
        "else:\n",
        "    print(f\"ERROR: The file was not found at {drive_zip_path}\")\n",
        "    print(\"Please double-check the file path and folder names in your Google Drive.\")\n",
        "\n",
        "# --- Step 4: Displaying Folder Contents ---\n",
        "print(\"\\n--- Verifying Extracted Contents ---\")\n",
        "\n",
        "# Walk through the extracted directory and print the structure\n",
        "if os.path.exists(extract_path):\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        # To keep the output clean, we'll just report the count of JSON files in sequence folders\n",
        "        if os.path.basename(root).endswith('-rgb_front'):\n",
        "            print(f\"\\nFolder: {root}\")\n",
        "            if files:\n",
        "                 print(f\"  Contains {len(files)} JSON files (e.g., {files[0]})\")\n",
        "            else:\n",
        "                 print(\"  Contains 0 JSON files.\")\n",
        "            continue\n",
        "\n",
        "        if root != extract_path:\n",
        "            print(f\"\\nFolder: {root}\")\n",
        "\n",
        "        if dirs:\n",
        "            print(f\"  Subdirectories: {dirs}\")\n",
        "\n",
        "        if files:\n",
        "            # Only show files for the top-level directories to avoid clutter\n",
        "            if root.count(os.sep) - extract_path.count(os.sep) < 2:\n",
        "                 print(\"  Files:\")\n",
        "                 for file in files:\n",
        "                    print(f\"    - {file}\")\n",
        "else:\n",
        "    print(f\"ERROR: The extraction directory '{extract_path}' was not created. Cannot list contents.\")\n",
        "\n",
        "print(\"\\n--- Verification Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def load_and_process_keypoints(sequence_path):\n",
        "    \"\"\"\n",
        "    Loads all JSON files from a sequence folder, extracts and concatenates the\n",
        "    x, y keypoints for pose, face, and hands, ignoring confidence scores.\n",
        "    \"\"\"\n",
        "    json_files = sorted([os.path.join(sequence_path, f) for f in os.listdir(sequence_path) if f.endswith('.json')])\n",
        "\n",
        "    sequence_data = []\n",
        "    for file_path in json_files:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if not data['people']:\n",
        "            # If no person was detected in the frame, append a zero vector.\n",
        "            # The number of features is 543 points * 2 coordinates = 1086.\n",
        "            # This needs to be consistent with frames that do have data.\n",
        "            # NOTE: We will calculate the exact feature count dynamically later.\n",
        "            continue\n",
        "\n",
        "        person = data['people'][0]\n",
        "\n",
        "        # Extract x, y coordinates, discarding confidence scores\n",
        "        pose_kps = np.array(person['pose_keypoints_2d']).reshape(-1, 3)[:, :2].flatten()\n",
        "        face_kps = np.array(person['face_keypoints_2d']).reshape(-1, 3)[:, :2].flatten()\n",
        "        hand_left_kps = np.array(person['hand_left_keypoints_2d']).reshape(-1, 3)[:, :2].flatten()\n",
        "        hand_right_kps = np.array(person['hand_right_keypoints_2d']).reshape(-1, 3)[:, :2].flatten()\n",
        "\n",
        "        # Concatenate all keypoints into a single feature vector for the frame\n",
        "        frame_features = np.concatenate([pose_kps, face_kps, hand_left_kps, hand_right_kps])\n",
        "        sequence_data.append(frame_features)\n",
        "\n",
        "    return np.array(sequence_data)\n",
        "\n",
        "# --- Main Script ---\n",
        "DATA_PATH = \"dev_test_data/json_keypoints\"\n",
        "sequence_folders = [os.path.join(DATA_PATH, seq) for seq in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, seq))]\n",
        "\n",
        "# Load all sequences from the disk\n",
        "all_sequences = []\n",
        "for sequence_path in sequence_folders:\n",
        "    sequence_keypoints = load_and_process_keypoints(sequence_path)\n",
        "    if sequence_keypoints.size > 0:\n",
        "        all_sequences.append(sequence_keypoints)\n",
        "\n",
        "if not all_sequences:\n",
        "    print(\"No data was loaded. Please check the DATA_PATH and folder structure.\")\n",
        "else:\n",
        "    # Pad sequences to ensure they all have the same length\n",
        "    # This is a requirement for creating a single NumPy array for the model\n",
        "    X = pad_sequences(all_sequences, padding='post', dtype='float32')\n",
        "\n",
        "    # The final shape will be (num_samples, max_frames, num_keypoints * 2)\n",
        "    # This is the \"X\" data for our model [cite: 62, 102]\n",
        "    print(\"--- Data Preprocessing Complete ---\")\n",
        "    print(f\"Final data shape (X): {X.shape}\")\n",
        "    print(f\"Number of sequences (videos) loaded: {X.shape[0]}\")\n",
        "    print(f\"Maximum frames in a sequence (padded): {X.shape[1]}\")\n",
        "    print(f\"Number of features per frame (keypoints): {X.shape[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB7Vhx5-ks8u",
        "outputId": "3a746974-387f-403a-dae5-f35221d9e3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Preprocessing Complete ---\n",
            "Final data shape (X): (5, 412, 274)\n",
            "Number of sequences (videos) loaded: 5\n",
            "Maximum frames in a sequence (padded): 412\n",
            "Number of features per frame (keypoints): 274\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- 0. 导入所有必需的库 ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- (请确保您已经从之前的Notebook复制了SignLanguageGenerator类的完整定义) ---\n",
        "class SignLanguageGenerator(Sequence):\n",
        "    def __init__(self, data_folder, labels_df, label_encoder, batch_size, num_classes):\n",
        "        self.data_folder = data_folder; self.labels_df = labels_df.copy(); self.label_encoder = label_encoder; self.batch_size = batch_size; self.num_classes = num_classes\n",
        "        print(f\"Verifying files for generator in '{self.data_folder}'...\")\n",
        "        all_disk_files = {os.path.splitext(f)[0] for f in os.listdir(self.data_folder) if f.endswith('.mp4')}\n",
        "        all_csv_files = set(self.labels_df['SENTENCE_NAME'].tolist()); valid_files = list(all_disk_files.intersection(all_csv_files))\n",
        "        self.video_files = valid_files; self.labels_df = self.labels_df[self.labels_df['SENTENCE_NAME'].isin(self.video_files)]\n",
        "        print(f\"Found {len(self.video_files)} valid and labeled video files.\")\n",
        "    def __len__(self): return math.floor(len(self.video_files) / self.batch_size)\n",
        "    def __getitem__(self, idx):\n",
        "        batch_files = self.video_files[idx * self.batch_size:(idx + 1) * self.batch_size]; batch_labels_df = self.labels_df[self.labels_df['SENTENCE_NAME'].isin(batch_files)]\n",
        "        X = np.zeros((len(batch_files), 30, 64, 64, 3), dtype=np.float32); y_text = []\n",
        "        for i, row in enumerate(batch_labels_df.itertuples()):\n",
        "            video_path = os.path.join(self.data_folder, row.SENTENCE_NAME + '.mp4'); cap = cv2.VideoCapture(video_path); frames = []\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret: break\n",
        "                resized_frame = cv2.resize(frame, (64, 64)); frames.append(resized_frame)\n",
        "            cap.release(); frames = np.array(frames)\n",
        "            if frames.size == 0: continue\n",
        "            if len(frames) > 30: frames = frames[:30]\n",
        "            elif len(frames) < 30:\n",
        "                pad_width = ((0, 30 - len(frames)), (0, 0), (0, 0), (0, 0)); frames = np.pad(frames, pad_width, mode='constant', constant_values=0)\n",
        "            X[i,] = frames / 255.0; y_text.append(row.SENTENCE)\n",
        "        try:\n",
        "            y_int = self.label_encoder.transform(y_text)\n",
        "            y = to_categorical(y_int, num_classes=self.num_classes)\n",
        "        except ValueError:\n",
        "            return np.zeros_like(X), np.zeros((X.shape[0], self.num_classes))\n",
        "        return X, y\n",
        "# --- (SignLanguageGenerator类定义结束) ---\n",
        "\n",
        "\n",
        "# --- 1. 加载我们保存的最佳模型 ---\n",
        "print(\"Loading the best CNN-LSTM model: cnn_lstm_frontal_model_v1.h5\")\n",
        "model_path = '/content/drive/MyDrive/train-CNN+LSTM+BO/cnn_lstm_frontal_model_v1.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# --- 2. 准备与训练时一致的标签编码器 ---\n",
        "# --- THIS IS THE FIX ---\n",
        "print(\"\\nLoading ONLY TRAIN+VAL label files to create a consistent encoder...\")\n",
        "base_drive_path = '/content/drive/MyDrive/train-CNN+LSTM+BO'\n",
        "# 定义三个CSV文件在Drive中的路径\n",
        "TRAIN_LABELS_CSV_GDRIVE = os.path.join(base_drive_path, 'how2sign_realigned_train.csv')\n",
        "VAL_LABELS_CSV_GDRIVE = os.path.join(base_drive_path, 'how2sign_realigned_val.csv')\n",
        "TEST_LABELS_CSV_GDRIVE = os.path.join(base_drive_path, 'how2sign_realigned_test.csv')\n",
        "# 复制到本地\n",
        "shutil.copy(TRAIN_LABELS_CSV_GDRIVE, 'how2sign_realigned_train.csv')\n",
        "shutil.copy(VAL_LABELS_CSV_GDRIVE, 'how2sign_realigned_val.csv')\n",
        "shutil.copy(TEST_LABELS_CSV_GDRIVE, 'how2sign_realigned_test.csv')\n",
        "\n",
        "# 只使用训练集和验证集来构建编码器\n",
        "train_labels_df = pd.read_csv('how2sign_realigned_train.csv', sep='\\t')\n",
        "val_labels_df = pd.read_csv('how2sign_realigned_val.csv', sep='\\t')\n",
        "train_val_labels_df = pd.concat([train_labels_df, val_labels_df], ignore_index=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_val_labels_df['SENTENCE'])\n",
        "NUM_CLASSES = len(label_encoder.classes_)\n",
        "print(f\"Total classes the model was trained on: {NUM_CLASSES}\") # 这应该是31592\n",
        "# --- END OF FIX ---\n",
        "\n",
        "\n",
        "# --- 3. 为测试集创建数据生成器 ---\n",
        "print(\"\\nCreating a generator for the TEST set...\")\n",
        "TEST_VIDEO_FOLDER = 'frontal_test_videos/raw_videos'\n",
        "test_labels_df = pd.read_csv('how2sign_realigned_test.csv', sep='\\t')\n",
        "\n",
        "# 关键：过滤测试集，只保留模型认识的标签\n",
        "known_classes = set(label_encoder.classes_)\n",
        "test_labels_df_filtered = test_labels_df[test_labels_df['SENTENCE'].isin(known_classes)]\n",
        "print(f\"Original test samples: {len(test_labels_df)}, Filtered test samples: {len(test_labels_df_filtered)}\")\n",
        "\n",
        "\n",
        "test_generator = SignLanguageGenerator(\n",
        "    data_folder=TEST_VIDEO_FOLDER,\n",
        "    labels_df=test_labels_df_filtered, # 使用过滤后的DataFrame\n",
        "    label_encoder=label_encoder,\n",
        "    batch_size=32,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "\n",
        "# --- 4. 在测试集上评估并生成报告 ---\n",
        "print(\"\\n--- Evaluating model on the official TEST data ---\")\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
        "print(f\"\\nOfficial Test Accuracy: {accuracy * 100:.4f}%\")\n",
        "print(f\"Official Test Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\nGenerating classification report...\")\n",
        "y_pred_one_hot = model.predict(test_generator)\n",
        "y_pred_labels = np.argmax(y_pred_one_hot, axis=1)\n",
        "\n",
        "num_test_samples = len(test_generator.video_files)\n",
        "batches_to_run = len(test_generator)\n",
        "samples_to_consider = batches_to_run * 32\n",
        "y_true_text = test_generator.labels_df['SENTENCE'].iloc[:samples_to_consider]\n",
        "y_true_int = label_encoder.transform(y_true_text)\n",
        "y_pred_labels = y_pred_labels[:len(y_true_int)]\n",
        "\n",
        "report = classification_report(y_true_int, y_pred_labels, output_dict=True, zero_division=0)\n",
        "print(f\"Official F1-score (macro avg): {report['macro avg']['f1-score']:.4f}\")\n",
        "print(\"--- Report Generation Elements Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCxnabQOHUQU",
        "outputId": "9abb8569-91ed-4ffd-99ff-597f9a739e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the best CNN-LSTM model: cnn_lstm_frontal_model_v1.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading ONLY TRAIN+VAL label files to create a consistent encoder...\n",
            "Total classes the model was trained on: 31592\n",
            "\n",
            "Creating a generator for the TEST set...\n",
            "Original test samples: 2357, Filtered test samples: 76\n",
            "Verifying files for generator in 'frontal_test_videos/raw_videos'...\n",
            "Found 76 valid and labeled video files.\n",
            "\n",
            "--- Evaluating model on the official TEST data ---\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 8.1313\n",
            "\n",
            "Official Test Accuracy: 0.0000%\n",
            "Official Test Loss: 8.1375\n",
            "\n",
            "Generating classification report...\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 470ms/step\n",
            "Official F1-score (macro avg): 0.0000\n",
            "--- Report Generation Elements Complete ---\n"
          ]
        }
      ]
    }
  ]
}